% lfw.tex
%
% Author       : James Mnatzaganian, Qutaiba Saleh
% Date Created : 05/04/15
%
% Description  : LFW Paper
%
% Copyright (c) 2014 NanoComputing Research Lab

% Define the document type
\documentclass[10pt,journal]{IEEEtran}

% Packages
\usepackage{cite}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{fixltx2e}
\usepackage{subcaption}

% Package configuration
\graphicspath{{figures/}}

% Macros
\newcommand{\fig}[1]{Fig.~\ref{#1}}
\newcommand{\eq}[1]{(\ref{#1})}
\newcommand{\tbl}[1]{Table~\ref{#1}}

% Add DRAFT to the document
\usepackage{watermark}
\watermark{\hspace{-0.3in} \textbf{DRAFT} \hspace{2.0in} \textbf{\today}}

\begin{document}
	
	\title{An Efficient Hardware Implementation of Competitive Learning Classifier for Gender Classification}
	
	\author{
		James~Mnatzaganian,~\IEEEmembership{Student Member,~IEEE,}
        and~Qutaiba~Saleh,~\IEEEmembership{Student Member,~IEEE}%
	
		\IEEEcompsocitemizethanks{
			\IEEEcompsocthanksitem J. Mnatzaganian, and Q. Saleh are with the NanoComputing Research Laboratory, Rochester Institute of Technology, Rochester, NY, 14623.
		}%
		
		\thanks{Manuscript received May 21, 2015.}
	}
	
	% \markboth{Journal of IEEE Transactions,~Vol.~?, No.~?, ?~2015}%
	
	\IEEEtitleabstractindextext{%
		\begin{abstract}
			TEXT
		\end{abstract}
	
	\begin{IEEEkeywords}
		Competitive Learning Classifier (CLC), gender classification, ASIC, low power.
	\end{IEEEkeywords}}

	\maketitle
	\IEEEdisplaynontitleabstractindextext
	
	\IEEEPARstart{G}{ender}
		classification is an important topic in social interactions. It can determine the greeting from one individual to another as well as the entire context of the conversation. Additionally, determining an individual's gender could be used to market products specifically for that gender. For example, a clothing store could have an automated advertising board to display products that would best suit the individual entering their store. If a gender detection system was being used in that manner, the system would need to be able to determine the gender classification in real-time, additionally it should consume as little power as possible.
		
		This problem has been explored by many software approaches (e.g.~\cite{sw_comparison,sw_svm,sw_cnn}), but only a couple hardware implementations exist~\cite{ann_fpga,svm_fpga}. For a real-time embedded system, the design should ideally be a low-power ASIC. None of the past designs created an ASIC and additionally none of those designs mentioned power consumption. This work developed a custom algorithm explicitly designed to be as efficient as possible while still achieving acceptable accuracies.
	
	\subsection{Dataset}
		The Labeled Faces in the Wild (LFW)~\cite{lfw} dataset was modified for use with gender classification. This dataset is comprised of one or more faces per person, with no labels to denote gender. To obtain the genders, the genderize.io~\cite{genderize} API was utilized. This API can be used to obtain the gender, with a confidence interval, for a given first name. Only results with over 90\% accuracy were utilized.
		
		The faces in the dataset are not all frontalized nor are they cropped to remove background noise. To remove noise, the frontalized images from Hassner et al.~\cite{frontalize} were used as the dataset. This dataset frontalized and cropped all images from the LFW dataset, creating a cleaner dataset. The images were then resized to various sizes using bilinear interpolation. The raw pixels were then used as the features.
		
		To ensure that the dataset would not be biased towards a particular individual, a single instance of each person was randomly chosen. The remaining images were then randomized and split by gender, to ensure an equal distribution of males and females. 400 of each gender were used for training and 200 of each gender were used for testing. All code for generating the dataset as well as the software and hardware models are available at~\cite{gitrepo}.
	
	\subsection{Design Approach}
		The primary design constraints were area and power. With this in mind, the system still had to perform its primary goal of gender classification. It was desired to obtain the highest possible accuracy; however, if a minor loss in accuracy resulted in major hardware improvements, favor was given to the hardware.
		
		\subsubsection{Algorithm}
			An algorithm similar to competitive learning was designed. This algorithm is coined Competitive Learning Classifier (CLC). The algorithm is comprised of \(N\) competitive learning networks, where \(N\) is the number of labels. Each network has \(I\) inputs and \(O\) outputs, where each output represents a cluster. The implementation of this algorithm used for this work is shown in \fig{fig:network}. It consists of two competitive learning networks (one for males and one for females), 49 inputs per network (one for each feature), and a single output for each network.
			
			In CLC, there is a randomly initialized weight for each input in each network. The weights are updated using the online update equation in \eq{sw_weight_update}, where \(w_{i,n}\) is the weight of input \(i\) for network \(n\), \(\alpha\) is the learning rate, \(\hat{y}_{o,n}^{(p)}\) is output \(o\) of network \(n\) for pattern \(p\), and \(u_i^{(p)}\) is input \(i\) for pattern \(p\). Each output is computed by finding the squared Euclidean distance between the weight and the input, as shown in \eq{sw_output}. The corresponding cost function is shown in \eq{cost_function}, where \(P\) is the total number of patterns.
			
			If \(O>1\) dead neurons may occur. To combat this, boosting is used, where frequently winning neurons are negatively boosted and infrequently winning neurons are positively boosted. Boosting is only updated during the learning phase, so after training the boost values are fixed.
			
			Training occurs by selecting the network representing the current label and updating its weights. The other networks are left untouched. During testing, both networks receive the same input and compute their respective outputs. The neuron having the lowest value is the winning neuron and the network that it belongs to becomes the output of the network.
			
			\begin{figure}
				\centering
				\includegraphics[width=0.8\linewidth]{network}
				\caption{A CLC consisting of two networks (male and female), 49 inputs per network, and a single output for each network.}
				\label{fig:network}
			\end{figure}
			
			\begin{equation}
				\label{sw_weight_update}
				\Delta w_{i,n} = \alpha\hat{y}_{o,n}^{(p)}(u_i^{(p)}-w_{i,n})
			\end{equation}
			
			\begin{equation}
				\label{sw_output}
				\hat{y}_{o,n}^{(p)} = \displaystyle\sum_{i=1}^{I}(w_{i,n} - u_i^{(p)})^2
			\end{equation}
			
			\begin{equation}
				\label{cost_function}
				J(\boldsymbol{w}_n) = \cfrac{1}{2}\displaystyle\sum_{p=1}^{P}\displaystyle\sum_{o=1}^{O}\hat{y}_{o,n}^{(p)}|\boldsymbol{w}_n-\boldsymbol{u}^{(p)}|^2
			\end{equation}
		
		\subsubsection{Software}
			The software design consisted of two phases. The first phase involved finding a set of parameters that would obtain suitable accuracies. Additionally, those parameters should be tweaked, if possible, to simplify the hardware. The second phase involved redesigning the CLC model to be identical to the hardware design. This includes any simplifications as well as performing calculations using the same precision that would be used in the hardware.
			
			\paragraph{Parameter Optimization}
				A fully generic software model of CLC was created in Python. This model supports \(I\) inputs, \(N\) networks, and \(O\) outputs. For gender classification only two networks are required (male and female); however, the number of inputs as well as outputs for each network can both be set to any suitable value. In addition to those parameters, a suitable learning rate had to be determined.
				
				To find suitable parameters, a simple search approach was taken, where one parameter was varied while all others were fixed. The best parameter from the current experiment was used in subsequent experiments. All simulations were performed 10 times for statistical purposes.
				
				The first parameter varied was the number of inputs, i.e. the image size. The number of outputs for each network was fixed at one and the learning rate was set to 0.001. The training and testing results are shown in \fig{fig:sw_img}. The full image size (30x30) produced the highest accuracy, as expected; however, an image size of 7x7 produced a similar level of accuracy and would reduce the number of inputs per network by over 18x. For this reason, an image size of 7x7 was chosen.
				
				The second parameter varied was the number of outputs. The image size was set to 7x7 and the learning rate was set to 0.001. The training and testing results are shown in \fig{fig:sw_outputs}. It is observed that a single output per network converges very quickly, while multiple outputs require hundreds of training epochs. Additionally, overfitting occurs once the number of epochs becomes too large. It is also observed that the variance increases drastically with multiple outputs. A final consideration is that once the number of outputs exceeds one, boosting must be performed. Boosting results in a substantial increase in HW complexity as it requires that a history of the past \(H\) outputs be stored per output. Additionally, an added computational strain is added for updating the boost values, calculating the network outputs, and selecting the network winner. For those reasons, a single output was chosen.
				
				The final varied parameter was the learning rate. The image size was set to 7x7 and the number of outputs for each network was fixed at one. The training and testing results are shown in \fig{fig:sw_learning_rate}. When the learning rate is within a suitable range, the system converges on a similar output. If the learning rate is too small, the system is unable to learn. If the learning rate is too high, the system is unable to expand upon its learning. A learning rate of 0.001 was chosen, as this resulted in the best accuracies with the fastest convergence. This learning rate is additionally within a range suitable for representation within hardware.
				
				\begin{figure*}[t!]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						Training results
						\label{fig:sw_img:training}
					}
					{\includegraphics[width=0.49\linewidth]{sw_img_training}}
					\hfill
					\subcaptionbox
					{
						Testing results
						\label{fig:sw_img:testing}
					}
					{\includegraphics[width=0.49\linewidth]{sw_img_testing}}
					\hfill
					\caption{Training~(\subref{fig:sw_img:training}) and testing~(\subref{fig:sw_img:testing}) results for various image sizes. Each network has a single output. The learning rate was set to 0.001.}
					\label{fig:sw_img}
				\end{figure*}
				
				\begin{figure*}[t!]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						Training results
						\label{fig:sw_outputs:training}
					}
					{\includegraphics[width=0.49\linewidth]{sw_outputs_training}}
					\hfill
					\subcaptionbox
					{
						Testing results
						\label{fig:sw_outputs:testing}
					}
					{\includegraphics[width=0.49\linewidth]{sw_outputs_testing}}
					\hfill
					\caption{Training~(\subref{fig:sw_outputs:training}) and testing~(\subref{fig:sw_outputs:testing}) results for a various number of network outputs. The image size was 7x7. The learning rate was set to 0.001.}
					\label{fig:sw_outputs}
				\end{figure*}
				
				\begin{figure*}[t!]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						Training results
						\label{fig:sw_learning_rate:training}
					}
					{\includegraphics[width=0.49\linewidth]{sw_learning_rate_training}}
					\hfill
					\subcaptionbox
					{
						Testing results
						\label{fig:sw_learning_rate:testing}
					}
					{\includegraphics[width=0.49\linewidth]{sw_learning_rate_testing}}
					\hfill
					\caption{Training~(\subref{fig:sw_learning_rate:training}) and testing~(\subref{fig:sw_learning_rate:testing}) results for various learning rates. The image size was 7x7. Each network has a single output.}
					\label{fig:sw_learning_rate}
				\end{figure*}
			
			\paragraph{Hardware Model}
				The CLC model was redesigned to follow the hardware model as closely as possible. Boosting was removed from the model as it was assumed that there would only be a single output from each network. It was desired to use the Q fixed-point number format for representing all numbers. A Python datatype was created to allow all required arithmetic operations to be performed as a native Python datatype. This allowed for multiple benefits, namely ensuring that the arithmetic would resolve to the same exact values as in the hardware (including overflow and underflow conditions) and allowing for a near seamless transition between the pure software model and this new model.
				
				In Q format it is important to know exactly what the bounds of the scalars will be. If they grow to be too large or too small, then they will no longer be able to be represented with the specified number of integer bits. Additionally, the level of precision must be noted. Each increase in decimal precision requires more fractional bits. With these concepts in mind, it is important to ensure that the numbers are all at a similar scale, as this will reduce the number of required bits. The chosen learning rate is 0.001, which is a relatively small number, and the magnitude of the weights and pixels are between zero and one. To keep the number of bits down, it was desired to ensure that the values did not exceed \(\pm{1}\), because only a single integer bit would be required.
				
				In \eq{sw_weight_update}, \(\hat{y}_{o,n}^{(p)}\) is always going to be equal to one, as there is only a single network output and this output must always be chosen to be the winning cluster. The difference of \(u_i^{(p)}\) and \(w_{i,n}\) is able to be between -2 and 2, so with a single integer bit it is possible to have overflow; however, it is an unlikely scenario and should not drastically affect the overall output, as an overflow would result in the max positive value being returned. More importantly, because both \(u_i^{(p)}\) and \(w_{i,n}\) are of the same scale, the operation will result in a similar returned scale. This value is then going to be scaled by \(\alpha\), reducing the resulting scale to be the same as \(\alpha\)'s. Since \(I < \alpha^{-1}\) it is not possible for the resulting weight to overflow. This allows for \eq{sw_weight_update} to be simply updated to \eq{hw_weight_update}.
				
				In \eq{sw_output}, the squared values of the difference of \(u_i^{(p)}\) and \(w_{i,n}\) are being summed. Squaring that difference will occur in an overflow in many cases. Additionally, summing those squared values will almost certainly result in an overflow. To address that problem, \eq{sw_output} is updated to be \eq{hw_output}, where \(C\) is a scaling factor defined to be \(I^{-1/2}\). This scaling factor ensures that the sum remains within a suitable range; additionally, performing the scaling operation before squaring eliminates overflow from that operation.
				
				\begin{equation}
					\label{hw_weight_update}
					\Delta w_{i,n} = \alpha(u_i^{(p)}-w_{i,n})
				\end{equation}
				
				\begin{equation}
					\label{hw_output}
					\hat{y}_{o,n}^{(p)} = \displaystyle\sum_{i=1}^{I}((w_{i,n} - u_i^{(p)})*C)^2
				\end{equation}
				
				This hardware model introduces another parameter, the number of suitable fractional bits. To determine the minimum number of required bits, this new model was simulated across a range of count of fractional bits. The training and testing results are shown in \fig{fig:fractional_bits}. As seen, once the number of fractional bits drops below 11 the system is no longer able to function. At 11 bits or above, the accuracies are similar, thus 11 bits were chosen. This results in a total of 13 bits per number, which is still much smaller than the number of bits that would be required if floating point had been used.
				
				\begin{figure*}[t!]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						Training results
						\label{fig:sw_fractional_bits:training}
					}
					{\includegraphics[width=0.49\linewidth]{sw_fractional_bits_training}}
					\hfill
					\subcaptionbox
					{
						Testing results
						\label{fig:sw_fractional_bits:testing}
					}
					{\includegraphics[width=0.49\linewidth]{sw_fractional_bits_testing}}
					\hfill
					\caption{Training~(\subref{fig:sw_fractional_bits:training}) and testing~(\subref{fig:sw_fractional_bits:testing}) results for a various count of fractional bits.}
					\label{fig:fractional_bits}
				\end{figure*}
		
		\subsubsection{Hardware}
The hardware implementation is designed to be identical to the software implementation. It is simply applying the two equations \eq{hw_output} and \eq{hw_weight_update} in hardware. Starting from these equations, the design can be divided into three main parts: two calculation blocks for weight update during training and output evaluate for testing and a register block to save the weights. These main components are controlled by a state machine. The system is structurally designed to allow flexibility in optimization and res-using purposes.  

As can be seen in \fig{fig:network} the network consists of two identical competitive networks. The hardware model makes use of this fact to reduce the size of the design of almost 50\%. One hardware network model was used for both of the male and female networks. This was achieved by saving the weight values for the networks in two separate registers while sharing the same calculation blocks. As this approach reduces the hardware and power costs it also reduces the performance of the design by 50\%. 

\fig{fig:System:block} shows the external inputs and outputs of the system. The Mode signal is used to select one of four different modes: Idle, Weight Initialization, Training, and Testing. During the Idle mode, the system is simply doing nothing except waiting for incoming inputs. The Initialization mode is used to generate the initial weights values. An LFSR is used to generate these weights. As seen in \fig{fig:System:block} the seed of the LFSR can be changed by the user. It is also shown that the learning rate (alpha) can be changed by the user. This gives the flexibility to generate different initial weights and train them under different alpha values which is vital for optimization purposes. The system has two outputs: "Output" and "Ready". "Output" is a one bit port indicating the gender of the input image while the system is working in test mode. "Ready" is a flag that is always active indicating that the system for the next training or testing vector except when the system is in Init. mode in which the system is busy initializing a new set of random weights for the next training process. A simplified internal architecture of the overall system is shown in \fig{fig:full:system}. 

	\begin{figure}[h]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						System inputs and outputs
						\label{fig:System:block}
					}
					{\includegraphics[width=0.9\columnwidth]{System_block}}
					\hfill
					\subcaptionbox
					{
						Internal structure
						\label{fig:full:system}
					}
					{\includegraphics[width=0.9\columnwidth]{Full_system}}
					\hfill
					\caption{System block~(\subref{fig:System:block}) explaining external inputs and outputs ~(\subref{fig:full:system}) showing the main components of the system: weight registers, weight update, output evaluate, an LFSR and a comparator.}
					\label{fig:hardware:system}
				\end{figure}
				
				
				
The state machine is the main control unit of the system. As shown in \fig{fig:state:machine} it has one input and four output flags. The input signal controls the transition between the four stats: Idle, Init., Train, and Test. Based on these states the statuses of the output flags are changed.  One external and three internal flags are driven by the state machine. The external flag is "Ready" which indicates the situation of the system. The other internal flags are: Test, Train and Reset. These flags are distributed to the rest components of the system to control their work.  The system starts with the Idle state weighting for any changes in the input signal "Mode". From Idle state, the state machine transits to all other states. Even though that it is applicable, it is not recommended to change between states without going through Idle state.

	\begin{figure}
				\centering
				\includegraphics[width=0.8\linewidth]{State_machine}
				\caption{State machine of the system. It has only one input (Mode) that controls the transition between the four states: Idle, Init., Test and Train. The four output flags control the work rest part of the system.}
				\label{fig:state:machine}
			\end{figure}
			
			
During Init. state, the weights are randomly generated and stored in the male and female weight registers. A 12-bits Linear Feedback Shift Register (LFSR) is used to generate the initial weights. The configuration of the LFSR is shown in \fig{fig:lfsr}. Once the reset flag is active, the LFSR component takes the seed value at the input port "$LFSR_init$" based on which it generates the initial weights. It generates one weight values every clock cycle. These values are serially fed into the male and female registers which are also connected in series. 

During Training state, the weights are updated by the weight update block. Each weight update process takes two clock cycles. In the first cycle and based on the label of the input training vector, the male or female weight block sets their weights active. The weight update block takes the assigned weights and calculates the updated weights based on the input image. In the second clock cycle, the new update weight values are saved into the associated weights register. The weight update block consists of a stack of identical smaller components. Each component is responsible for updating one weight value. They are hardware implementations of \eq{hw_weight_update}. The internal structure of one weight update component is shown in \fig{fig:weight:update}. Alpha is parametrized by the user and it is distributed to all weight update components in the weight update block. 

There is no limit to the number of training vectors that the system can learn. The user can keep feeding new vectors as long as the mode signal is set to train mode "10". Once the training process is completed, the mode signal should be set back to Idle "00". Otherwise, the system will continue the training process based on the value available at the input port which probably would be the last training vector. 

In the test state, the output evaluate block is used to calculate the output value of the network. The output evaluate block is a hardware implementation of  \eq{hw_output}. It consists of a stack of one pixels output evaluate component followed by an adder tree which represents the summation in \eq{hw_output}. The internal structure of the output evaluate component is shown in \fig{fig:output:evaluate}. The scale factor used in this component is saved in a register located in the output evaluate block and distributed to all components in the block. This block takes only one clock cycle to evaluate the output of a network. Since this block is used to evaluate outputs of both male and female networks, two clock cycles are required to calculate the final output. 


	\begin{figure}[h]
					\captionsetup[subfigure]{position=b}
					\centering
					\hfill
					\subcaptionbox
					{
						LFSR
						\label{fig:lfsr}
					}
					{\includegraphics[width=0.9\columnwidth]{LFSR}}
					\hfill
					\subcaptionbox
					{
						Weight update
						\label{fig:weight:update}
					}
					{\includegraphics[width=0.9\columnwidth]{Weight_update}}
					\hfill
					\subcaptionbox
					{
						Output evaluate
						\label{fig:output:evaluate}
					}
					{\includegraphics[width=0.9\columnwidth]{Output_evaluate}}
					\hfill
					\caption{~(\subref{fig:weight:update})  Linear Feedback shift register (LFSR) configuration. ~(\subref{fig:weight:update}) Weight update structure for only weight. The weight update block consists of a stack of this structure.  ~(\subref{fig:output:evaluate}) Output evaluate structure for one input pixel. The output evaluate block consists of a stack of this structure followed by an adder-tree.}
					\label{fig:output:evaluate}
				\end{figure}
				
				
Sharing the output evaluate block between the two networks requires more control signals to synchronize the pipeline process between the networks. The network select block is used for this purpose \fig{fig:full:system}. It is a clock divider that has an output control signal clocking at half system clock frequency. This signal is used as a select signal for the multiplexer at the input of the weight update block. It is also used as an enable signal for the register at the output of the output evaluate block. This register is used to save the output value of the male network. The output of this register and the output of the weight update are connected to a comparator components to make the final classification decision. 
	
	\subsection{Results}
		The hardware design was initially tested in ModelSim. The same training and testing strategy used in the software were used for the hardware. The results are shown in \tbl{table:accuracy_results}, where the final accuracies, along with their corresponding standard deviations, were obtained after 20 training epochs across 10 iterations. It was expected to obtain very close, if not identical, results between the two implementations. The hardware accuracies are roughly 2\% less than the software accuracies. This discrepancy could be due to the initialized weight values, as the hardware and software models used 10 different random states. Multiple iterations were performed; however, the total iterations is still relatively small. Given this and the fact that the accuracies are similar, the hardware was validated.
		
		The hardware design was synthesized with Synopsis' DC Compiler for TSMC018 process. The footprint of the design was 0.0176 mm^2.
		
		The total power of the system was measured to be 31.6 mW across all 30 epochs.
		
		Given the extremely small size, this design is suitable for many embedded applications.
		
		
		
		\begin{table}[!t]
			\renewcommand{\arraystretch}{1.3}
			\caption{Accuracies for the Hardware and Software Models After 20 Epochs}
			\label{table:accuracy_results}
			\centering
			\begin{tabular}{ccc}
				\hline
				         & Train Accuracy           & Test Accuracy           \\
				\hline
				Hardware & 68.363 \(\pm\) 0.401  \% & 67.850 \(\pm\) 0.950 \% \\
				Software & 70.125 \(\pm\) 0.0791 \% & 70.300 \(\pm\) 0.332 \% \\
				\hline
			\end{tabular}
		\end{table}		
	
	\section{Conclusion}
		TEXT
	
	% Bibliography
	\bibliographystyle{IEEEtran}
		\bibliography{IEEEabrv,lfw}
	
\end{document}